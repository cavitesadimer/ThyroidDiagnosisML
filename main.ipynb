import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, learning_curve
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, precision_recall_curve
import matplotlib.pyplot as plt
import seaborn as sns

# Veri setini URL ile çekme
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/thyroid-disease/new-thyroid.data"

df = pd.read_csv(url, header=None, delimiter=',')

# Kolon isimleri
column_names = ['Class', 'T3_resin', 'Total_serum_thyroxin', 'Total_serum_triiodothyronine', 'Basal_TSH', 'Maximal_absolute_diff_TSH']
df.columns = column_names

print("Veri setinin ilk birkaç satırı:")
print(df.head())

X = df.drop('Class', axis=1)
y = df['Class']

# Özniteliklerin dağılımı
df.hist(figsize=(12, 10))
plt.suptitle('Özniteliklerin Dağılımları')
plt.show()

# Scatter plot ile öznitelikler arasındaki ilişkilerin görselleştirilmesi
sns.pairplot(df, hue='Class', diag_kind='kde')
plt.suptitle('Öznitelikler Arası İlişkiler', y=1.02)
plt.show()

# Korelasyon matrisi
corr_matrix = df.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Korelasyon Matrisi')
plt.show()

# Box Plot ve olası aykırı değerlerin gösterilmesi
plt.figure(figsize=(12, 10))
sns.boxplot(data=df.drop('Class', axis=1))
plt.title('Özniteliklerin Box Plotları')
plt.xticks(rotation=90)
plt.show()

# Eğitim ve test oranları
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Veri ölçeklendirme
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# k=3
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train_scaled, y_train)

# KNN Tahmin yapma
y_pred_knn = knn.predict(X_test_scaled)
y_prob_knn = knn.predict_proba(X_test_scaled)[:, 1]

# KNN Modelinin performansı
knn_score = knn.score(X_test_scaled, y_test)
knn_report = classification_report(y_test, y_pred_knn, output_dict=True)
print("3-NN Score: {:.4f}".format(knn_score))
print("\nKNN Karmasiklik Matrisi:")
print(confusion_matrix(y_test, y_pred_knn))
print("\nKNN Siniflandirma Raporu:")
print(classification_report(y_test, y_pred_knn))

# KArar ağaci
dt_model = DecisionTreeClassifier()
dt_model.fit(X_train_scaled, y_train)

# Karar ağaci tahmin
y_pred_dt = dt_model.predict(X_test_scaled)
y_prob_dt = dt_model.predict_proba(X_test_scaled)[:, 1]

# Karar ağaci performans değerlerndirmesi
dt_accuracy = accuracy_score(y_test, y_pred_dt)
dt_report = classification_report(y_test, y_pred_dt, output_dict=True)
print("Karar agaci Model Doğruluk Oranı: {:.4f}".format(dt_accuracy))
print("\nKarar agaci Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_dt))
print("\nKarar agaci Siniflandirma Raporu:")
print(classification_report(y_test, y_pred_dt))

# Yalın Bayes
gnb = GaussianNB()
gnb.fit(X_train_scaled, y_train)

# Yalın Bayes Tahmin
y_pred_gnb = gnb.predict(X_test_scaled)
y_prob_gnb = gnb.predict_proba(X_test_scaled)[:, 1]

# Yalın bayes performansı
gnb_accuracy = accuracy_score(y_test, y_pred_gnb)
gnb_report = classification_report(y_test, y_pred_gnb, output_dict=True)
print("Yalin Bayes Model Doğruluk Oranı: {:.4f}".format(gnb_accuracy))
print("\nYalin Bayes Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_gnb))
print("\nYalin Bayes Siniflandirma Raporu:")
print(classification_report(y_test, y_pred_gnb))

# (SVM) modeli
svm_model = SVC(probability=True)
svm_model.fit(X_train_scaled, y_train)

# SVM Tahmin yapma
y_pred_svm = svm_model.predict(X_test_scaled)
y_prob_svm = svm_model.predict_proba(X_test_scaled)[:, 1]

# SVM Modelinin performansı
svm_accuracy = accuracy_score(y_test, y_pred_svm)
svm_report = classification_report(y_test, y_pred_svm, output_dict=True)
print("SVM Model Doğruluk Oranı: {:.4f}".format(svm_accuracy))
print("\nSVM Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_svm))
print("\nSVM Siniflandirma Raporu:")
print(classification_report(y_test, y_pred_svm))

# RandomForestClassifier modeli
rf_model = RandomForestClassifier()
rf_model.fit(X_train_scaled, y_train)

# Random Forest Tahmin
y_pred_rf = rf_model.predict(X_test_scaled)
y_prob_rf = rf_model.predict_proba(X_test_scaled)[:, 1]

# Random Forest Modelinin performansı
rf_accuracy = accuracy_score(y_test, y_pred_rf)
rf_report = classification_report(y_test, y_pred_rf, output_dict=True)
print("Random Forest Model Doğruluk Oranı: {:.4f}".format(rf_accuracy))
print("\nRandom Forest Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_rf))
print("\nRandom Forest Siniflandirma Raporu:")
print(classification_report(y_test, y_pred_rf))

# Model performanslarının görselleştirilmesi
models = ['KNN', 'Decision Tree', 'GaussianNB', 'SVM', 'Random Forest']
accuracy_scores = [knn_score, dt_accuracy, gnb_accuracy, svm_accuracy, rf_accuracy]

plt.figure(figsize=(10, 5))
plt.bar(models, accuracy_scores, color=['blue', 'green', 'red', 'purple', 'orange'])
plt.ylim([0, 1])
plt.title('Model Doğruluk Oranları')
plt.xlabel('Modeller')
plt.ylabel('Doğruluk Oranı')
for i in range(len(models)):
    plt.text(i, accuracy_scores[i] + 0.01, f"{accuracy_scores[i]:.4f}", ha='center', va='bottom')
plt.show()

# Karmaşıklık matrisleri
fig, axes = plt.subplots(2, 3, figsize=(20, 10))

# KNN Karmaşıklık Matrisi
sns.heatmap(confusion_matrix(y_test, y_pred_knn), annot=True, fmt='d', ax=axes[0, 0], cmap='Blues')
axes[0, 0].set_title('KNN Karmaşıklık Matrisi')
axes[0, 0].set_xlabel('Tahmin Edilen')
axes[0, 0].set_ylabel('Gerçek')

# Decision Tree Karmaşıklık Matrisi
sns.heatmap(confusion_matrix(y_test, y_pred_dt), annot=True, fmt='d', ax=axes[0, 1], cmap='Greens')
axes[0, 1].set_title('Decision Tree Karmaşıklık Matrisi')
axes[0, 1].set_xlabel('Tahmin Edilen')
axes[0, 1].set_ylabel('Gerçek')

# GaussianNB Karmaşıklık Matrisi
sns.heatmap(confusion_matrix(y_test, y_pred_gnb), annot=True, fmt='d', ax=axes[0, 2], cmap='Reds')
axes[0, 2].set_title('GaussianNB Karmaşıklık Matrisi')
axes[0, 2].set_xlabel('Tahmin Edilen')
axes[0, 2].set_ylabel('Gerçek')

# SVM Karmaşıklık Matrisi
sns.heatmap(confusion_matrix(y_test, y_pred_svm), annot=True, fmt='d', ax=axes[1, 0], cmap='Purples')
axes[1, 0].set_title('SVM Karmaşıklık Matrisi')
axes[1, 0].set_xlabel('Tahmin Edilen')
axes[1, 0].set_ylabel('Gerçek')

# Random Forest Karmaşıklık Matrisi
sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', ax=axes[1, 1], cmap='Oranges')
axes[1, 1].set_title('Random Forest Karmaşıklık Matrisi')
axes[1, 1].set_xlabel('Tahmin Edilen')
axes[1, 1].set_ylabel('Gerçek')

plt.show()

# ROC ve AUC eğrileri
fpr_knn, tpr_knn, _ = roc_curve(y_test, y_prob_knn, pos_label=1)
fpr_dt, tpr_dt, _ = roc_curve(y_test, y_prob_dt, pos_label=1)
fpr_gnb, tpr_gnb, _ = roc_curve(y_test, y_prob_gnb, pos_label=1)
fpr_svm, tpr_svm, _ = roc_curve(y_test, y_prob_svm, pos_label=1)
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf, pos_label=1)

plt.figure(figsize=(10, 8))
plt.plot(fpr_knn, tpr_knn, color='blue', label='KNN (AUC = {:.4f})'.format(auc(fpr_knn, tpr_knn)))
plt.plot(fpr_dt, tpr_dt, color='green', label='Karar Ağaci (AUC = {:.4f})'.format(auc(fpr_dt, tpr_dt)))
plt.plot(fpr_gnb, tpr_gnb, color='red', label='Yalin Bayes (AUC = {:.4f})'.format(auc(fpr_gnb, tpr_gnb)))
plt.plot(fpr_svm, tpr_svm, color='purple', label='SVM (AUC = {:.4f})'.format(auc(fpr_svm, tpr_svm)))
plt.plot(fpr_rf, tpr_rf, color='orange', label='Random Forest (AUC = {:.4f})'.format(auc(fpr_rf, tpr_rf)))
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.title('ROC Eğrisi ve AUC')
plt.xlabel('Yanlış Pozitif Rate')
plt.ylabel('Dogru Pozitif Rate')
plt.legend(loc='lower right')
plt.show()

# Precision-Recall eğrileri
precision_knn, recall_knn, _ = precision_recall_curve(y_test, y_prob_knn, pos_label=1)
precision_dt, recall_dt, _ = precision_recall_curve(y_test, y_prob_dt, pos_label=1)
precision_gnb, recall_gnb, _ = precision_recall_curve(y_test, y_prob_gnb, pos_label=1)
precision_svm, recall_svm, _ = precision_recall_curve(y_test, y_prob_svm, pos_label=1)
precision_rf, recall_rf, _ = precision_recall_curve(y_test, y_prob_rf, pos_label=1)

plt.figure(figsize=(10, 8))
plt.plot(recall_knn, precision_knn, color='blue', label='KNN')
plt.plot(recall_dt, precision_dt, color='green', label='Decision Tree')
plt.plot(recall_gnb, precision_gnb, color='red', label='GaussianNB')
plt.plot(recall_svm, precision_svm, color='purple', label='SVM')
plt.plot(recall_rf, precision_rf, color='orange', label='Random Forest')
plt.title('Precision-Recall Eğrisi')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.legend(loc='upper right')
plt.show()

# Model performans karşılaştırması
metrics_df = pd.DataFrame({
    'Model': ['KNN', 'Decision Tree', 'GaussianNB', 'SVM', 'Random Forest'],
    'Accuracy': [knn_report['accuracy'], dt_report['accuracy'], gnb_report['accuracy'], svm_report['accuracy'], rf_report['accuracy']],
    'Precision': [knn_report['macro avg']['precision'], dt_report['macro avg']['precision'], gnb_report['macro avg']['precision'], svm_report['macro avg']['precision'], rf_report['macro avg']['precision']],
    'Recall': [knn_report['macro avg']['recall'], dt_report['macro avg']['recall'], gnb_report['macro avg']['recall'], svm_report['macro avg']['recall'], rf_report['macro avg']['recall']],
    'F1-Score': [knn_report['macro avg']['f1-score'], dt_report['macro avg']['f1-score'], gnb_report['macro avg']['f1-score'], svm_report['macro avg']['f1-score'], rf_report['macro avg']['f1-score']]
})

metrics_df.set_index('Model').plot(kind='bar', figsize=(12, 8), ylim=[0, 1])
plt.title('Model Performans Karşılaştırması')
plt.ylabel('Skor')
plt.xlabel('Modeller')
plt.xticks(rotation=0)
plt.legend(loc='lower right')
plt.show()

# Öğrenme eğrileri
def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):
    plt.figure()
    plt.title(title)
    if ylim is not None:
        plt.ylim(*ylim)
    plt.xlabel("Training examples")
    plt.ylabel("Score")
    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.grid()

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color="g")
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r", label="Training score")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g", label="Cross-validation score")

    plt.legend(loc="best")
    return plt

plot_learning_curve(KNeighborsClassifier(n_neighbors=3), 'Öğrenme Eğrisi (KNN)', X_train_scaled, y_train)
plt.show()

plot_learning_curve(DecisionTreeClassifier(), 'Öğrenme Eğrisi (Karar Ağaci)', X_train_scaled, y_train)
plt.show()

plot_learning_curve(GaussianNB(), 'Öğrenme Eğrisi (Yalin Bayes)', X_train_scaled, y_train)
plt.show()

plot_learning_curve(SVC(probability=True), 'Öğrenme Eğrisi (SVM)', X_train_scaled, y_train)
plt.show()

plot_learning_curve(RandomForestClassifier(), 'Öğrenme Eğrisi (Random Forest)', X_train_scaled, y_train)
plt.show()

# Karar ağaci için özellik önem düzeyleri
dt_model.fit(X_train, y_train)
importances = dt_model.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(10, 8))
plt.title("Özellik Önem Düzeyleri (Karar Agaci)")
plt.bar(range(X.shape[1]), importances[indices], align="center")
plt.xticks(range(X.shape[1]), [X.columns[i] for i in indices], rotation=90)
plt.xlim([-1, X.shape[1]])
plt.show()
